{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-28T17:38:02.668866Z",
     "start_time": "2024-05-28T17:38:00.635767Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "from scipy.fft import dctn, idctn\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "\n",
    "from preprocessing.transforms import CompressedToTensor, ZigZagOrder, ChooseAC, FlattenZigZag, ConvertToFrequencyDomain, ConvertToYcbcr, Quantize, LUMINANCE_QUANTIZATION_MATRIX, CHROMINANCE_QUANTIZATION_MATRIX\n",
    "from model.init import init_truncated_normal, init_kaiming_normal, set_seed\n",
    "from model.vit import CompressedVisionTransformer, VisionTransformer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T17:38:02.672212Z",
     "start_time": "2024-05-28T17:38:02.669954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DOWNLAOD_PATH = os.path.join('data', 'cifar10')\n",
    "SEED = 42\n",
    "VALIDATION_SET = 0.1\n",
    "BATCH_SIZE = 128\n",
    "AC = 5"
   ],
   "id": "ad18146e091b5c14",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T17:38:02.674688Z",
     "start_time": "2024-05-28T17:38:02.672708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "quantization_matrices = [LUMINANCE_QUANTIZATION_MATRIX, CHROMINANCE_QUANTIZATION_MATRIX, CHROMINANCE_QUANTIZATION_MATRIX]\n",
    "\n",
    "if_you_want_to_get_an_RGB_image = Compose([\n",
    "    ToTensor()\n",
    "    # Returns pixels in range [0-1]\n",
    "])\n",
    "\n",
    "\n",
    "transform = Compose([\n",
    "    CompressedToTensor(), # 3x32x32\n",
    "    # Returns pixels in range [0-255]\n",
    "    ConvertToYcbcr(), # 3x32x32\n",
    "    # Returns pixels in range [0-1]\n",
    "    ConvertToFrequencyDomain(norm='ortho'), # 3x32x32\n",
    "    Quantize(quantization_matrices=quantization_matrices, alpha=1.0, floor=True), # 3x32x32\n",
    "    ZigZagOrder(), # 3x16x64\n",
    "    ChooseAC(AC), # 3x16x(AC+1)\n",
    "    FlattenZigZag() # 16x(3x(AC+1))\n",
    "])\n"
   ],
   "id": "ed6eac04e65c0b13",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T17:38:03.436525Z",
     "start_time": "2024-05-28T17:38:02.675196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cifar = CIFAR10(root=DOWNLAOD_PATH, train=True, transform=transform, target_transform=None, download = False)\n",
    "cifar_test = CIFAR10(root=DOWNLAOD_PATH, train=False, transform=transform, target_transform=None, download = False)"
   ],
   "id": "f5f4bac3251a44f6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T17:38:03.445149Z",
     "start_time": "2024-05-28T17:38:03.438316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with set_seed(SEED): # For reproducible results run any random operations with set_seed()\n",
    "    num_train = len(cifar)\n",
    "    num_val = int(0.1 * num_train)\n",
    "    num_train -= num_val\n",
    "\n",
    "    cifar_train, cifar_val = random_split(cifar, [num_train, num_val])"
   ],
   "id": "3dc0d39523bc9225",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T17:38:03.448598Z",
     "start_time": "2024-05-28T17:38:03.446305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = DataLoader(cifar_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val = DataLoader(cifar_val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test = DataLoader(cifar_test, batch_size=cifar_test.__len__(), shuffle=False)"
   ],
   "id": "7c00df673219726e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Example training",
   "id": "ac43531a75fa7c7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T17:38:03.472819Z",
     "start_time": "2024-05-28T17:38:03.449532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_PARAMETERS = {\n",
    "    'ac':AC, # Required for proper positional encoding\n",
    "    'channels':3,\n",
    "    'patch_num':16,\n",
    "    'num_classes':10,\n",
    "    'd_model':248,\n",
    "    'nhead':8,\n",
    "    'dim_feedforward':1024,\n",
    "    'dropout':0.1,\n",
    "    'activation':'gelu',\n",
    "    'ntransformers':4,\n",
    "    'layer_norm_eps':1e-5,\n",
    "    'norm_first':False,\n",
    "    'bias':True,\n",
    "    'learnable_positional':True\n",
    "}\n",
    "\n",
    "\n",
    "model = CompressedVisionTransformer(**MODEL_PARAMETERS)\n",
    "\n",
    "model.pre_training() # ViT's are pretrained with a 2 layer head instead of 1 layer head\n",
    "\n",
    "with set_seed(SEED): # For reproducible results run any random operations with set_seed()\n",
    "    model.init_weights(init_truncated_normal) # Truncated Normal is consistent with original ViT paper\n",
    "    # For CNN's use init_kaiming_normal"
   ],
   "id": "f3286c2f2a6cf87b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T17:38:03.476836Z",
     "start_time": "2024-05-28T17:38:03.473618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "experiment_name = f'bart_experiment_example'\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 1e-4\n",
    "num_epochs = 10\n",
    "weight_decay = 0\n",
    "checkpoint_every_th_epoch = None #TODO: Add periodic checkpointing\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ],
   "id": "bfc8d6df8a590f54",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Parameter tracking for MLFlow",
   "id": "a659e00c190aa597"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T17:38:04.692820Z",
     "start_time": "2024-05-28T17:38:04.688822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PREPROCESSING_PARAMETERS = {\n",
    "    f'step_{i}': type(t).__name__ for i, t in enumerate(transform.transforms)\n",
    "}\n",
    "\n",
    "TRAINING_PARAMETERS = {\n",
    "    \"criterion\":type(criterion).__name__,\n",
    "    \"optimizer_type\": type(optimizer).__name__,\n",
    "    \"seed\":SEED,\n",
    "    \"batch_size\":BATCH_SIZE,\n",
    "    \"validation\":VALIDATION_SET,\n",
    "    **optimizer.defaults\n",
    "}\n",
    "\n",
    "MODEL_PARAMETERS = {\n",
    "    \"model\": type(model).__name__,\n",
    "    **MODEL_PARAMETERS\n",
    "}"
   ],
   "id": "201349af12af1d81",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_experiment(experiment_name)\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"preprocessing_steps\", json.dumps(PREPROCESSING_PARAMETERS))\n",
    "    mlflow.log_param(\"training_parameters\", json.dumps(TRAINING_PARAMETERS))\n",
    "    mlflow.log_param(\"model_parameters\", json.dumps(MODEL_PARAMETERS))\n",
    "\n",
    "\n",
    "    with set_seed(SEED):\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            for images, labels in train:\n",
    "                images, labels = images.to(torch.float32), labels\n",
    "        \n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "                train_loss += loss.item() * images.size(0)\n",
    "        \n",
    "            train_loss /= len(train)\n",
    "\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "        \n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in val:\n",
    "                    images, labels = images.to(torch.float32), labels\n",
    "        \n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "        \n",
    "                    val_loss += loss.item() * images.size(0)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    \n",
    "                    \n",
    "        \n",
    "            val_loss /= len(val)\n",
    "            val_accuracy = correct / total\n",
    "            mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "            mlflow.log_metric(\"val_accuracy\", val_accuracy, step=epoch)\n",
    "        \n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            #TODO: Add more metrics\n",
    "            #TODO: Add creating an artifact out of the final model"
   ],
   "id": "d253adb5e9e5465c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
