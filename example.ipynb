{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T17:52:57.400028Z",
     "start_time": "2024-05-17T17:52:54.939635Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.fft import dctn, idctn\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "\n",
    "from preprocessing.transforms import CompressedToTensor, ZigZagOrder, ChooseAC, FlattenZigZag, ConvertToFrequencyDomain, ConvertToYcbcr, Quantize, LUMINANCE_QUANTIZATION_MATRIX, CHROMINANCE_QUANTIZATION_MATRIX\n",
    "from model.init import init_truncated_normal, init_kaiming_normal, set_seed\n",
    "from model.vit import CompressedVisionTransformer, VisionTransformer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T17:52:57.402722Z",
     "start_time": "2024-05-17T17:52:57.400984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DOWNLAOD_PATH = os.path.join('data', 'cifar10')\n",
    "SEED = 42\n",
    "VALIDATION_SET = 0.1\n",
    "BATCH_SIZE = 128\n",
    "AC = 5"
   ],
   "id": "ad18146e091b5c14",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T17:52:57.406091Z",
     "start_time": "2024-05-17T17:52:57.403342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "quantization_matrices = [LUMINANCE_QUANTIZATION_MATRIX, CHROMINANCE_QUANTIZATION_MATRIX, CHROMINANCE_QUANTIZATION_MATRIX]\n",
    "\n",
    "vanilla_transform = Compose([\n",
    "    ToTensor()\n",
    "    # Returns pixels in range [0-1]\n",
    "])\n",
    "\n",
    "transform = Compose([\n",
    "    CompressedToTensor(), # 3x32x32\n",
    "    # Returns pixels in range [0-255]\n",
    "    ConvertToYcbcr(), # 3x32x32\n",
    "    # Returns pixels in range [0-1]\n",
    "    ConvertToFrequencyDomain(norm='ortho'), # 3x32x32\n",
    "    Quantize(quantization_matrices=quantization_matrices), # 3x32x32\n",
    "    ZigZagOrder(), # 3x16x64\n",
    "    ChooseAC(AC), # 3x16x(AC+1)\n",
    "    FlattenZigZag() # 3x(16x(AC+1))\n",
    "])"
   ],
   "id": "ed6eac04e65c0b13",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T17:52:58.160840Z",
     "start_time": "2024-05-17T17:52:57.407167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cifar = CIFAR10(root=DOWNLAOD_PATH, train=True, transform=transform, target_transform=None, download = False)\n",
    "cifar_test = CIFAR10(root=DOWNLAOD_PATH, train=False, transform=transform, target_transform=None, download = False)"
   ],
   "id": "f5f4bac3251a44f6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T17:52:58.191524Z",
     "start_time": "2024-05-17T17:52:58.161986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with set_seed(SEED): # For reproducible results run any random operations with set_seed()\n",
    "    num_train = len(cifar)\n",
    "    num_val = int(0.1 * num_train)\n",
    "    num_train -= num_val\n",
    "\n",
    "    cifar_train, cifar_val = random_split(cifar, [num_train, num_val])"
   ],
   "id": "3dc0d39523bc9225",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T17:52:58.196140Z",
     "start_time": "2024-05-17T17:52:58.192688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = DataLoader(cifar_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val = DataLoader(cifar_val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test = DataLoader(cifar_test, batch_size=cifar_test.__len__(), shuffle=False)"
   ],
   "id": "7c00df673219726e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Example training",
   "id": "ac43531a75fa7c7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T17:53:21.460610Z",
     "start_time": "2024-05-17T17:53:21.430322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_PARAMETERS = {\n",
    "    'ac':AC, # Required for proper positional encoding\n",
    "    'channels':3,\n",
    "    'patch_num':16,\n",
    "    'num_classes':10,\n",
    "    'd_model':248,\n",
    "    'nhead':8,\n",
    "    'dim_feedforward':1024,\n",
    "    'dropout':0.1,\n",
    "    'activation':'gelu',\n",
    "    'ntransformers':4,\n",
    "    'layer_norm_eps':1e-5,\n",
    "    'norm_first':False,\n",
    "    'bias':True,\n",
    "    'learnable_positional':True\n",
    "}\n",
    "\n",
    "\n",
    "model = CompressedVisionTransformer(**MODEL_PARAMETERS)\n",
    "\n",
    "model.pre_training() # ViT's are pretrained with a 2 layer head instead of 1 layer head\n",
    "\n",
    "with set_seed(SEED): # For reproducible results run any random operations with set_seed()\n",
    "    model.init_weights(init_truncated_normal) # Truncated Normal is consistent with original ViT paper\n",
    "    # For CNN's use init_kaiming_normal"
   ],
   "id": "f3286c2f2a6cf87b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T17:56:08.743063Z",
     "start_time": "2024-05-17T17:56:08.737973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 1e-4\n",
    "num_epochs = 10\n",
    "weight_decay = 0\n",
    "checkpoint_every_th_epoch = None #TODO: implement\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ],
   "id": "bfc8d6df8a590f54",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Parameter tracking for MLFlow",
   "id": "a659e00c190aa597"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T17:56:09.207424Z",
     "start_time": "2024-05-17T17:56:09.202476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TRAINING_PARAMETERS = {\n",
    "    \"criterion\":type(criterion).__name__,\n",
    "    \"optimizer_type\": type(optimizer).__name__,\n",
    "    \"seed\":SEED,\n",
    "    \"batch_size\":BATCH_SIZE,\n",
    "    **optimizer.defaults\n",
    "}\n",
    "\n",
    "MODEL_PARAMETERS = {\n",
    "    \"model\": type(model).__name__,\n",
    "    **MODEL_PARAMETERS\n",
    "}"
   ],
   "id": "201349af12af1d81",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T17:26:22.614342Z",
     "start_time": "2024-05-17T17:26:22.589665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with set_seed(SEED):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in train:\n",
    "            images, labels = images.to(torch.float32), labels\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "    \n",
    "        train_loss /= len(train)\n",
    "    \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val:\n",
    "                images, labels = images.to(torch.float32), labels\n",
    "    \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "    \n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                #TODO: Add more metrics\n",
    "    \n",
    "        val_loss /= len(val)\n",
    "        val_accuracy = correct / total\n",
    "    \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')"
   ],
   "id": "d253adb5e9e5465c",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cvit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m set_seed(SEED):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m----> 3\u001B[0m         \u001B[43mcvit\u001B[49m\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m      4\u001B[0m         train_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m      5\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m images, labels \u001B[38;5;129;01min\u001B[39;00m train:\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cvit' is not defined"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "817e34d2231a8e5b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
