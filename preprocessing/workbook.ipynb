{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch import nn\n",
    "from dataset import CIFAR10_custom\n",
    "from transforms import CompressedToTensor\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "torch.set_printoptions(threshold=10_000)\n",
    "# np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "download_path = os.path.join('..', 'data', 'cifar10')\n",
    "\n",
    "if not os.path.exists(download_path):\n",
    "    os.makedirs(download_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = Compose([CompressedToTensor()])\n",
    "with_zig_zag = Compose([CompressedToTensor(),\n",
    "                        ZigZagOrder()])\n",
    "\n",
    "cifar = CIFAR10_custom(download_path, transform = transform,  download = True)\n",
    "cifar2 = CIFAR10_custom(download_path, transform = transform,  download = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "'rgb'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar.format"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.2314, 0.1686, 0.1961,  ..., 0.6196, 0.5961, 0.5804],\n         [0.0627, 0.0000, 0.0706,  ..., 0.4824, 0.4667, 0.4784],\n         [0.0980, 0.0627, 0.1922,  ..., 0.4627, 0.4706, 0.4275],\n         ...,\n         [0.8157, 0.7882, 0.7765,  ..., 0.6275, 0.2196, 0.2078],\n         [0.7059, 0.6784, 0.7294,  ..., 0.7216, 0.3804, 0.3255],\n         [0.6941, 0.6588, 0.7020,  ..., 0.8471, 0.5922, 0.4824]],\n\n        [[0.2431, 0.1804, 0.1882,  ..., 0.5176, 0.4902, 0.4863],\n         [0.0784, 0.0000, 0.0314,  ..., 0.3451, 0.3255, 0.3412],\n         [0.0941, 0.0275, 0.1059,  ..., 0.3294, 0.3294, 0.2863],\n         ...,\n         [0.6667, 0.6000, 0.6314,  ..., 0.5216, 0.1216, 0.1333],\n         [0.5451, 0.4824, 0.5647,  ..., 0.5804, 0.2431, 0.2078],\n         [0.5647, 0.5059, 0.5569,  ..., 0.7216, 0.4627, 0.3608]],\n\n        [[0.2471, 0.1765, 0.1686,  ..., 0.4235, 0.4000, 0.4039],\n         [0.0784, 0.0000, 0.0000,  ..., 0.2157, 0.1961, 0.2235],\n         [0.0824, 0.0000, 0.0314,  ..., 0.1961, 0.1961, 0.1647],\n         ...,\n         [0.3765, 0.1333, 0.1020,  ..., 0.2745, 0.0275, 0.0784],\n         [0.3765, 0.1647, 0.1176,  ..., 0.3686, 0.1333, 0.1333],\n         [0.4549, 0.3686, 0.3412,  ..., 0.5490, 0.3294, 0.2824]]])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar[0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "cifar.to_ycbcr(in_place=True)\n",
    "output = cifar.compress(in_place=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "compressed_img = cifar[0][0]\n",
    "compressed_batch = torch.from_numpy(cifar.data[0:4,:,:,:].transpose((0, 3, 1, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "ex = torch.rand((4, 3, 32, 32))\n",
    "ex2 = torch.rand((3, 32, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 1024])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(ex, -2, -1).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.shape[:-2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "for channels in ex2.shape[:-2]:\n",
    "    print(channels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "def _zigzag_order(block: torch.Tensor) -> torch.Tensor:\n",
    "    # Zigzag index pattern for an 8x8 block\n",
    "    zigzag_indices = torch.tensor([\n",
    "        0, 1, 8, 16, 9, 2, 3, 10, 17, 24, 32, 25, 18, 11, 4, 5,\n",
    "        12, 19, 26, 33, 40, 48, 41, 34, 27, 20, 13, 6, 7, 14, 21, 28,\n",
    "        35, 42, 49, 56, 57, 50, 43, 36, 29, 22, 15, 23, 30, 37, 44, 51,\n",
    "        58, 59, 52, 45, 38, 31, 39, 46, 53, 60, 61, 54, 47, 55, 62, 63\n",
    "    ])\n",
    "\n",
    "    # Flatten the block and reorder it using the zigzag indices\n",
    "    flat_block = block.flatten()\n",
    "    zigzag_block = flat_block[zigzag_indices]\n",
    "\n",
    "    return zigzag_block"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "def _blockwise_zigzag_order(image: torch.Tensor, block_size: tuple[int, int] = (8, 8)) -> torch.Tensor:\n",
    "\n",
    "    img_height, img_width = image.shape\n",
    "    block_height, block_width = block_size\n",
    "    block_height_num, block_width_num = img_height//block_height, img_width//block_width\n",
    "    zigzag_length = block_size[0] * block_size[1]\n",
    "\n",
    "    zigzag_patches = torch.zeros((block_height_num, block_width_num, zigzag_length), dtype = torch.int8)\n",
    "\n",
    "\n",
    "    for i in range(0, img_height, block_height):\n",
    "        for j in range(0, img_width, block_width):\n",
    "            block = image[i:i+block_height, j:j+block_width]\n",
    "            zigzag_block = _zigzag_order(block)\n",
    "            zigzag_patches[i//block_height, j//block_width, :] = zigzag_block\n",
    "\n",
    "    return zigzag_patches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "def zigzag_order(image: torch.Tensor, block_size: tuple[int, int] = (8, 8)) -> torch.Tensor:\n",
    "    batch_size = image.shape[:-3]\n",
    "    channels = image.shape[-3]\n",
    "\n",
    "    unfold = torch.nn.Unfold(kernel_size=block_size, stride=block_size)\n",
    "    windows = unfold(image).transpose(-2, -1).view(*batch_size, -1, channels, block_size[0]*block_size[1]).transpose(-2, -3)\n",
    "\n",
    "    print(windows.shape)\n",
    "    return windows[..., zigzag_indices]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 37., -13.,  -7.,   3.,  -7.,  -4.,   1.,   2.,   1.,   2.,   1.,   1.,\n          3.,   1.,   0.,   0.,   0.,   0.,   0.,   1.,   1.,   1.,   1.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.], dtype=torch.float64)"
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_zigzag_order(compressed_img[:, 0:8, 0:8])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 32, 32])\n",
      "tensor([[ 37., -13.,  -4.,   1.,   0.,   0.,   0.,   0.],\n",
      "        [ -7.,  -7.,   2.,   1.,   0.,   0.,   0.,   0.],\n",
      "        [  3.,   1.,   3.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  2.,   1.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  1.,   1.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  1.,   1.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "unfold = torch.nn.Unfold(kernel_size=(8,8), stride=(8,8))\n",
    "print(compressed_batch.shape)\n",
    "print(compressed_batch[0, 0, 0:8, 0:8])\n",
    "unfolded = unfold(compressed_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 3, 32, 32])"
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_batch.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unfold() missing 2 required positional arguments: 'input' and 'kernel_size'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[180], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunctional\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munfold\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: unfold() missing 2 required positional arguments: 'input' and 'kernel_size'"
     ]
    }
   ],
   "source": [
    "torch.nn.functional.unfold()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 37., -13.,  -7.,   3.,  -7.,  -4.,   1.,   2.,   1.,   2.,   1.,   1.,\n          3.,   1.,   0.,   0.,   0.,   0.,   0.,   1.,   1.,   1.,   1.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.], dtype=torch.float64)"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_zigzag_order(unfolded.transpose(1, 2)[0, :, :64])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "trans = unfolded.transpose(-2, -1).view(4, -1, 3, 64).transpose(-2, -3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([16, 64])"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[0, 0, :, :].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "zigzag_indices = torch.tensor([\n",
    "    0, 1, 8, 16, 9, 2, 3, 10, 17, 24, 32, 25, 18, 11, 4, 5,\n",
    "    12, 19, 26, 33, 40, 48, 41, 34, 27, 20, 13, 6, 7, 14, 21, 28,\n",
    "    35, 42, 49, 56, 57, 50, 43, 36, 29, 22, 15, 23, 30, 37, 44, 51,\n",
    "    58, 59, 52, 45, 38, 31, 39, 46, 53, 60, 61, 54, 47, 55, 62, 63\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 37., -13.,  -7.,   3.,  -7.,  -4.,   1.,   2.,   1.,   2.,   1.,   1.,\n           3.,   1.,   0.,   0.,   0.,   0.,   0.,   1.,   1.,   1.,   1.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.],\n        [ 42.,   4.,   7.,   0.,  -5.,   1.,   0.,   1.,   5.,   3.,   2.,   0.,\n           0.,   1.,  -1.,   0.,   0.,   0.,   0.,   0.,   2.,   0.,   0.,   0.,\n           1.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.],\n        [ 44.,  -2.,   8.,   0.,  -2.,   4.,   1.,  -4.,   4.,  -1.,   4.,  -2.,\n           3.,   0.,   0.,   0.,   1.,   0.,  -1.,   1.,   0.,   0.,  -1.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.],\n        [ 45.,   8.,   9.,   6.,  -5.,  -2.,   0.,  -2.,  -2.,  -1.,   3.,   3.,\n           1.,   0.,  -1.,   0.,   1.,  -1.,   0.,  -1.,   2.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.],\n        [ 50.,  12.,   3.,  -2.,  -5.,  -1.,  -1.,   2.,   0.,  -2.,  -2.,   1.,\n           1.,   0.,   1.,   0.,  -1.,  -1.,   0.,  -1.,   0.,   0.,  -1.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.],\n        [ 55., -11., -23.,  -2.,  16.,   5.,  -3.,   3.,   5.,   2.,   0.,  -3.,\n           2.,   4.,  -1.,   1.,   1.,  -3.,  -3.,   1.,   0.,   0.,   0.,   0.,\n          -1.,  -1.,   0.,   0.,   0.,   0.,  -1.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.],\n        [ 72.,   8., -36.,   3.,   2.,  -1.,   2.,  -1.,   3.,  -1.,   2.,   4.,\n           4.,   1.,  -1.,   0.,  -1.,  -2.,   0.,   1.,   1.,   0.,  -1.,   0.,\n          -1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.],\n        [ 51.,   3.,  -5.,   2.,  -7.,   2.,   1.,  -5.,   4.,  -1.,   0.,  -1.,\n           3.,  -3.,   1.,   0.,  -1.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   1.,  -1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.],\n        [ 54.,  -6.,  -3.,  -5.,   5.,   8.,  -2.,   0.,   9.,   0.,   2.,   0.,\n          -5.,  -2.,   3.,   0.,   1.,   1.,   0.,  -2.,  -1.,   0.,   1.,   1.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.],\n        [ 80.,   7.,  11.,   1.,  -4.,   2.,   6.,   8.,  -8.,  -5.,  -3.,  -1.,\n          -1.,  -1.,  -1.,  -2.,  -2.,  -4.,   1.,   1.,   0.,   0.,   1.,   0.,\n          -2.,  -1.,  -1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.],\n        [ 73.,  -6.,  23.,   3.,  -2.,   7.,  -1.,   5.,  11.,   2.,   2.,   4.,\n          -2.,  -2.,   0.,   0.,   1.,  -1.,   1.,  -1.,   1.,   0.,  -1.,   0.,\n          -1.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.],\n        [ 58.,   5.,   2.,   4.,  12.,  13.,   2.,   2.,  -3.,   1.,  -2.,   0.,\n          -4.,   5.,   3.,   0.,   1.,  -2.,  -1.,   1.,   0.,   0.,   0.,   0.,\n           1.,  -1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.],\n        [ 65.,   4., -12.,   2.,   1.,   5.,   2.,   3.,  -8.,   0.,   1.,   1.,\n          -2.,   0.,   1.,   1.,   1.,   1.,  -2.,   0.,  -1.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.],\n        [ 59.,   1.,   6.,  10.,  -3.,  -1.,   3.,  -2.,   0.,   1.,   3.,  -1.,\n           0.,   1.,   0.,   0.,   0.,   0.,  -1.,   0.,  -1.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.],\n        [ 51.,   4.,  -2.,  -1.,  -1.,  -2.,  -1.,   0.,   4.,  -3.,   0.,   2.,\n           0.,   0.,   1.,   0.,   0.,   1.,  -2.,   1.,   0.,   0.,   0.,  -1.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.],\n        [ 53.,  -3.,   8.,   1.,  -3.,  -5.,  10.,   1.,  -7.,  -6.,   2.,   3.,\n           4.,  -4.,  -3.,  -1.,  -1.,  -2.,   1.,   1.,  -1.,   0.,   0.,  -1.,\n          -1.,   0.,   1.,   1.,   0.,  -1.,   1.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           0.,   0.,   0.,   0.]], dtype=torch.float64)"
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = trans[:, :, :, zigzag_indices]\n",
    "final[0, 0, :, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [],
   "source": [
    "check3 = _blockwise_zigzag_order(compressed_img[0, :, :])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 16, 64])\n"
     ]
    }
   ],
   "source": [
    "check1 = zigzag_order(compressed_batch)[0, 0, :, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16, 64])\n"
     ]
    }
   ],
   "source": [
    "check2 = zigzag_order(compressed_img)[0, :, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True]])"
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check1 == check2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True, True, True, True, True, True, True, True, True,\n         True, True, True, True]])"
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check3.view(-1, 64) == check1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 3, 16, 64])"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfolded.transpose(-2, -1).view(4, 16, 3, -1).transpose(-2, -3).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 192, 16])"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfolded.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 16, 64])"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}